{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuned PHI 4 Mini - Financial Aid Chat Usecase \n",
    "\n",
    "This notebook pulls down the Microsoft PHI 4 Mini model from HuggingFace and leverages a pre-made synthetic dataset comprising of fictitious recipient records. LoRA adapters were used to fine-tune the model efficiently, reducing memory usage by keeping the base model frozen and training only additional adapter layers. No real data is used in this dataset and the code is free from any conflict of interest to the best of the author's knowledge. This author assumes the user has a HuggingFace token and has set their GPU setting to MPS (requires MacOS 13+).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a virtual environment and run make install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import dependencies and deal with memory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-28T20:44:07.025608Z",
     "iopub.status.busy": "2025-02-28T20:44:07.025302Z",
     "iopub.status.idle": "2025-02-28T20:44:14.767623Z",
     "shell.execute_reply": "2025-02-28T20:44:14.766946Z",
     "shell.execute_reply.started": "2025-02-28T20:44:07.025585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import boto3\n",
    "\n",
    "# For LLM\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from chat_ai.src.domain.trainers.recipient_model_trainer import RecipientModelTrainer\n",
    "from chat_ai.src.domain.datasets.instruct_dataset import StudentDialogueDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T20:44:14.973802Z",
     "iopub.status.busy": "2025-02-28T20:44:14.973527Z",
     "iopub.status.idle": "2025-02-28T20:44:15.057514Z",
     "shell.execute_reply": "2025-02-28T20:44:15.056757Z",
     "shell.execute_reply.started": "2025-02-28T20:44:14.973779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The following helps with the MPS memory issue\n",
    "torch.mps.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Datasets and Synthetic Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T20:44:15.058623Z",
     "iopub.status.busy": "2025-02-28T20:44:15.058340Z",
     "iopub.status.idle": "2025-02-28T20:44:15.073394Z",
     "shell.execute_reply": "2025-02-28T20:44:15.072605Z",
     "shell.execute_reply.started": "2025-02-28T20:44:15.058599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load Data to Fine Tune LlaMa\n",
    "root_path = '../dist/data'\n",
    "train_df = pd.read_csv(f\"{root_path}/train_data.csv\", index_col=0)\n",
    "eval_df = pd.read_csv(f\"{root_path}/eval_data.csv\", index_col=0)\n",
    "synthetic_student_population_df = pd.read_csv(f\"{root_path}/synthetic_population_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T20:44:16.020110Z",
     "iopub.status.busy": "2025-02-28T20:44:16.019805Z",
     "iopub.status.idle": "2025-02-28T20:44:16.030843Z",
     "shell.execute_reply": "2025-02-28T20:44:16.030002Z",
     "shell.execute_reply.started": "2025-02-28T20:44:16.020086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>user_input</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student Linda Bailey (ID: S00001) has a GPA of...</td>\n",
       "      <td>What financial aid do I qualify for?</td>\n",
       "      <td>You qualify for the Need-Based Grant because y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student John Doe (ID: S00002) has a GPA of 3.8...</td>\n",
       "      <td>What financial aid am I eligible for?</td>\n",
       "      <td>John Doe qualifies for the Merit-Based Scholar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student Sarah Carter (ID: S00003) has a GPA of...</td>\n",
       "      <td>Can I apply for any financial aid?</td>\n",
       "      <td>Yes! You qualify for the STEM Excellence Award...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student John Doe (ID: S10123) has a GPA of 2.3...</td>\n",
       "      <td>What am I to be eligible for financial aid?</td>\n",
       "      <td>Due to your income, you do not qualify for a n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Student Linda Bailey (ID: S00001) has a GPA of...   \n",
       "1  Student John Doe (ID: S00002) has a GPA of 3.8...   \n",
       "2  Student Sarah Carter (ID: S00003) has a GPA of...   \n",
       "3  Student John Doe (ID: S10123) has a GPA of 2.3...   \n",
       "\n",
       "                                    user_input  \\\n",
       "0         What financial aid do I qualify for?   \n",
       "1        What financial aid am I eligible for?   \n",
       "2           Can I apply for any financial aid?   \n",
       "3  What am I to be eligible for financial aid?   \n",
       "\n",
       "                                              answer  \n",
       "0  You qualify for the Need-Based Grant because y...  \n",
       "1  John Doe qualifies for the Merit-Based Scholar...  \n",
       "2  Yes! You qualify for the STEM Excellence Award...  \n",
       "3  Due to your income, you do not qualify for a n...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T20:44:17.779584Z",
     "iopub.status.busy": "2025-02-28T20:44:17.779248Z",
     "iopub.status.idle": "2025-02-28T20:44:17.787570Z",
     "shell.execute_reply": "2025-02-28T20:44:17.786707Z",
     "shell.execute_reply.started": "2025-02-28T20:44:17.779555Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>user_input</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student Emily Carter (ID: S00023) has a GPA of...</td>\n",
       "      <td>Am I eligible for any financial aid?</td>\n",
       "      <td>Yes, you qualify for the STEM Excellence Award...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student Mark Smith (ID: S00045) has a GPA of 2...</td>\n",
       "      <td>Can I get coverage with my education program?</td>\n",
       "      <td>Unfortunately, you do not qualify for any fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student Olivia Jones (ID: S00030) has a GPA of...</td>\n",
       "      <td>Which financial aid can do I qualify for?</td>\n",
       "      <td>You qualify for the STEM Excellence Award sinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student Daniel Thompson (ID: S00051) has a GPA...</td>\n",
       "      <td>What financial aid options do I have?</td>\n",
       "      <td>You are eligible for the Need-Based Grant sinc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Student Emily Carter (ID: S00023) has a GPA of...   \n",
       "1  Student Mark Smith (ID: S00045) has a GPA of 2...   \n",
       "2  Student Olivia Jones (ID: S00030) has a GPA of...   \n",
       "3  Student Daniel Thompson (ID: S00051) has a GPA...   \n",
       "\n",
       "                                      user_input  \\\n",
       "0           Am I eligible for any financial aid?   \n",
       "1  Can I get coverage with my education program?   \n",
       "2      Which financial aid can do I qualify for?   \n",
       "3          What financial aid options do I have?   \n",
       "\n",
       "                                              answer  \n",
       "0  Yes, you qualify for the STEM Excellence Award...  \n",
       "1  Unfortunately, you do not qualify for any fina...  \n",
       "2  You qualify for the STEM Excellence Award sinc...  \n",
       "3  You are eligible for the Need-Based Grant sinc...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T20:44:19.257118Z",
     "iopub.status.busy": "2025-02-28T20:44:19.256803Z",
     "iopub.status.idle": "2025-02-28T20:44:19.267573Z",
     "shell.execute_reply": "2025-02-28T20:44:19.266846Z",
     "shell.execute_reply.started": "2025-02-28T20:44:19.257093Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>gpa</th>\n",
       "      <th>field_of_study</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S00001</td>\n",
       "      <td>Marc Solomon</td>\n",
       "      <td>2.53</td>\n",
       "      <td>Anthropology</td>\n",
       "      <td>73706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S00002</td>\n",
       "      <td>Suzanne Kidd</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Business Administration</td>\n",
       "      <td>22259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S00003</td>\n",
       "      <td>Michelle Griffin</td>\n",
       "      <td>2.42</td>\n",
       "      <td>Political Science</td>\n",
       "      <td>31192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S00004</td>\n",
       "      <td>Hannah Dixon</td>\n",
       "      <td>2.05</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>530431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S00005</td>\n",
       "      <td>Mary Harris</td>\n",
       "      <td>3.13</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>370142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>S00996</td>\n",
       "      <td>Nicole Clay</td>\n",
       "      <td>3.97</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>353792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>S00997</td>\n",
       "      <td>Tammy Rose</td>\n",
       "      <td>3.34</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>414283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>S00998</td>\n",
       "      <td>Jeff Alvarez</td>\n",
       "      <td>3.96</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>450287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>S00999</td>\n",
       "      <td>Thomas Lowe</td>\n",
       "      <td>3.02</td>\n",
       "      <td>Business Administration</td>\n",
       "      <td>54775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>S01000</td>\n",
       "      <td>Veronica Barker</td>\n",
       "      <td>3.29</td>\n",
       "      <td>Anthropology</td>\n",
       "      <td>270061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id              name   gpa           field_of_study  income\n",
       "0    S00001      Marc Solomon  2.53             Anthropology   73706\n",
       "1    S00002      Suzanne Kidd  2.50  Business Administration   22259\n",
       "2    S00003  Michelle Griffin  2.42        Political Science   31192\n",
       "3    S00004      Hannah Dixon  2.05              Engineering  530431\n",
       "4    S00005       Mary Harris  3.13                Chemistry  370142\n",
       "..      ...               ...   ...                      ...     ...\n",
       "995  S00996       Nicole Clay  3.97                Chemistry  353792\n",
       "996  S00997        Tammy Rose  3.34         Computer Science  414283\n",
       "997  S00998      Jeff Alvarez  3.96               Psychology  450287\n",
       "998  S00999       Thomas Lowe  3.02  Business Administration   54775\n",
       "999  S01000   Veronica Barker  3.29             Anthropology  270061\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_student_population_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load PHI 4 Mini Model and Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set logging level\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Get a logger instance for the app\n",
    "logger = logging.getLogger(__name__)  # Use __name__ to get module-level logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T20:44:24.404784Z",
     "iopub.status.busy": "2025-02-28T20:44:24.404423Z",
     "iopub.status.idle": "2025-02-28T20:45:02.100261Z",
     "shell.execute_reply": "2025-02-28T20:45:02.099315Z",
     "shell.execute_reply.started": "2025-02-28T20:44:24.404754Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 22:13:58,421 - INFO - Model will be moved to mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from microsoft/Phi-4-mini-instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6c1b9b7f8c4e86b14525092d816d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 22:14:02,686 - INFO - Model loaded in 4.26 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully and set to use mps!\n",
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "trainable params: 3,145,728 || all params: 3,839,167,488 || trainable%: 0.0819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erosado/work/rag-ai-chat-template/venv/lib/python3.12/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "# Import Base Model (used for all use cases)\n",
    "model_name = \"Phi-4-mini-instruct\"\n",
    "model_path = \"microsoft/Phi-4-mini-instruct\"\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "model_trainer = RecipientModelTrainer(\n",
    "    model_name=model_path, \n",
    "    dataset=train_df,\n",
    "    logger=logger, \n",
    "    device=device, \n",
    "    model_type=\"causal\",\n",
    "    huggingface_token=os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    ")\n",
    "\n",
    "model, tokenizer = model_trainer.load_model(\n",
    "    apply_lora=True, \n",
    "    lora_target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"fc1\", \"fc2\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T20:45:34.121337Z",
     "iopub.status.busy": "2025-02-28T20:45:34.120991Z",
     "iopub.status.idle": "2025-02-28T20:45:34.130460Z",
     "shell.execute_reply": "2025-02-28T20:45:34.129639Z",
     "shell.execute_reply.started": "2025-02-28T20:45:34.121305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = StudentDialogueDataset(train_df.to_dict(orient='records'), tokenizer, task_type=\"instruct\", device=device)\n",
    "eval_dataset = StudentDialogueDataset(eval_df.to_dict(orient='records'), tokenizer, task_type=\"instruct\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_dir = \"../dist/models/phi4_mini/chat/checkpoints\"\n",
    "lora_adapter_path = \"../dist/models/phi4_mini/chat/lora_adapter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T20:45:38.534861Z",
     "iopub.status.busy": "2025-02-28T20:45:38.534500Z",
     "iopub.status.idle": "2025-02-28T20:45:47.154630Z",
     "shell.execute_reply": "2025-02-28T20:45:47.153728Z",
     "shell.execute_reply.started": "2025-02-28T20:45:38.534830Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-11 22:14:39,847] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to mps (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erosado/work/rag-ai-chat-template/venv/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "W0311 22:14:39.978000 79982 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.743078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.740966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.734684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.710366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7.345200</td>\n",
       "      <td>7.661146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 22:15:17,835 - INFO - Model LoRA adapter files saved at ../dist/models/phi4_mini/chat/lora_adapter\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=checkpoints_dir,\n",
    "    per_device_train_batch_size=2,  # Reduce batch size for MPS stability\n",
    "    per_device_eval_batch_size=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=5,\n",
    "    bf16=True,\n",
    "    dataloader_pin_memory=False,\n",
    "    report_to=\"none\",\n",
    "    warmup_steps=100,\n",
    ")\n",
    "\n",
    "model_trainer.train(\n",
    "    training_arguments=training_args, \n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=eval_dataset, \n",
    "    output_dir=checkpoints_dir,\n",
    "    adapter_path=lora_adapter_path,\n",
    "    pad_to_multiple_of=8, \n",
    "    return_tensors=\"pt\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cache ahead of merge and unload\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 22:17:53,377 - INFO - Model will be moved to mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from microsoft/Phi-4-mini-instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97dad98df034308bb3f37a7b6cbf07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 22:17:56,201 - INFO - Model loaded in 2.82 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully and set to use mps!\n",
      "\n",
      "Merged Phi-4-mini-instruct model saved (base model + LoRA adapters)!\n",
      "Model saved to ../dist/models/phi4_mini/chat/v1.0\n",
      "S3 Model will be saved to models/phi4_mini/chat/v1.0\n"
     ]
    }
   ],
   "source": [
    "# Load Base Model\n",
    "device = torch.device(\"mps\")\n",
    "new_model_trainer = RecipientModelTrainer(\n",
    "    model_name=model_path, \n",
    "    dataset=train_df, \n",
    "    logger=logger,\n",
    "    device=device, \n",
    "    model_type=\"causal\",\n",
    "    huggingface_token=os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    ")\n",
    "base_model, tokenizer = new_model_trainer.load_model(apply_lora=False)\n",
    "\n",
    "# Load LoRA Adapters\n",
    "model = new_model_trainer.load_lora_adapters(\n",
    "    base_model, \n",
    "    lora_adapter_path, \n",
    "    merge_adapters=True  # Merge adapters into base model\n",
    "    )\n",
    "\n",
    "# Save the Fully Fine-Tuned Model\n",
    "tuned_version = 1\n",
    "tuned_model_name = \"chat\"\n",
    "tuned_model_storage_dir = f\"../dist/models/phi4_mini/{tuned_model_name}\"\n",
    "tuned_model_storage_path = f\"{tuned_model_storage_dir}/v{tuned_version}.0\"\n",
    "s3_model_storage_dir = f\"models/phi4_mini/{tuned_model_name}/v{tuned_version}.0\"\n",
    "\n",
    "model.save_pretrained(tuned_model_storage_path)\n",
    "tokenizer.save_pretrained(tuned_model_storage_path)\n",
    "\n",
    "print(f\"\\nMerged {model_name} model saved (base model + LoRA adapters)!\")\n",
    "print(f\"Model saved to {tuned_model_storage_path}\")\n",
    "print(f\"S3 Model will be saved to {s3_model_storage_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until this point, that is all that is required for full download, fine-tune, and saving of fine-tuned model. The remainder of this notebook is on using the model for the student chat use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Preprocess Synthetic Recipient Population Data\n",
    "Using the synthetic population dataset, construct prompts to test out the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T20:47:50.055858Z",
     "iopub.status.busy": "2025-02-28T20:47:50.055511Z",
     "iopub.status.idle": "2025-02-28T20:47:50.064590Z",
     "shell.execute_reply": "2025-02-28T20:47:50.063750Z",
     "shell.execute_reply.started": "2025-02-28T20:47:50.055829Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 student records available\n",
      "\n",
      "Data record shape:\n",
      "\n",
      "{'id': 'S00001', 'name': 'Marc Solomon', 'gpa': 2.53, 'field_of_study': 'Anthropology', 'income': 73706}\n"
     ]
    }
   ],
   "source": [
    "fake_students = synthetic_student_population_df.to_dict(orient=\"records\")\n",
    "\n",
    "print(f\"{len(fake_students)} student records available\")\n",
    "print(\"\\nData record shape:\\n\")\n",
    "print(fake_students[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T20:49:30.117116Z",
     "iopub.status.busy": "2025-02-28T20:49:30.116783Z",
     "iopub.status.idle": "2025-02-28T20:49:30.124595Z",
     "shell.execute_reply": "2025-02-28T20:49:30.123604Z",
     "shell.execute_reply.started": "2025-02-28T20:49:30.117093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "@staticmethod\n",
    "def determine_financial_aid_eligibility(gpa, field_of_study, income):\n",
    "    \"\"\"\n",
    "    Uses a student record to determine coverage against some fictitious\n",
    "    parameters\n",
    "    \"\"\"\n",
    "    # Dummy logic for financial aid eligibility\n",
    "    financial_aid = []\n",
    "    requirements = []\n",
    "\n",
    "    if gpa >= 3.6:\n",
    "        requirements.append(\"GPA ≥ 3.6\")\n",
    "    if income <= 35000:\n",
    "        requirements.append(\"Income ≤ $35,000\")\n",
    "    if field_of_study in [\n",
    "        \"Computer Science\",\n",
    "        \"Engineering\",\n",
    "        \"Mathematics\",\n",
    "        \"IT\",\n",
    "        \"Statistics\",\n",
    "    ]:\n",
    "        financial_aid.append(\"STEM Excellence Award\")\n",
    "        requirements.append(\"Field of Study in STEM\")\n",
    "    if field_of_study in [\"Psychology\", \"Sociology\", \"Social Work\", \"Anthropology\"]:\n",
    "        financial_aid.append(\"Behavioral and Social Sciences Grant\")\n",
    "        requirements.append(\"Field of Study in Behavioral and Social Sciences\")\n",
    "    if field_of_study in [\"Paralegal\", \"Law\"]:\n",
    "        financial_aid.append(\"Legal Studies Full Ride\")\n",
    "        requirements.append(\"Field of Study in Legal Studies\")\n",
    "\n",
    "    return requirements, financial_aid\n",
    "\n",
    "def retrieve_financial_aid_knowledge(student_id: Optional[str] = None, student_name: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Retrieves financial aid eligibility knowledge for a student.\n",
    "    \"\"\"\n",
    "    if student_id:\n",
    "        student = next((item for item in fake_students if item[\"id\"] == student_id), None)\n",
    "    if student_name:\n",
    "        student = next((item for item in fake_students if item[\"name\"] == student_name), None)\n",
    "\n",
    "    if not student:\n",
    "        return None\n",
    "\n",
    "    requirements, financial_aid = determine_financial_aid_eligibility(\n",
    "        student[\"gpa\"], student[\"field_of_study\"], student[\"income\"]\n",
    "        )\n",
    "        \n",
    "\n",
    "    return {\n",
    "        \"id\": student[\"id\"],\n",
    "        \"name\": student[\"name\"],\n",
    "        \"gpa\": student[\"gpa\"],\n",
    "        \"field_of_study\": student[\"field_of_study\"],\n",
    "        \"income\": student[\"income\"],\n",
    "        \"financial_aid\": financial_aid,\n",
    "        \"requirements\": requirements,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T21:01:19.393542Z",
     "iopub.status.busy": "2025-02-28T21:01:19.393197Z",
     "iopub.status.idle": "2025-02-28T21:01:19.399775Z",
     "shell.execute_reply": "2025-02-28T21:01:19.398958Z",
     "shell.execute_reply.started": "2025-02-28T21:01:19.393516Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'S00001', 'name': 'Marc Solomon', 'gpa': 2.53, 'field_of_study': 'Anthropology', 'income': 73706, 'financial_aid': ['Behavioral and Social Sciences Grant'], 'requirements': ['Field of Study in Behavioral and Social Sciences']}\n",
      "Recipient Marc Solomon (ID: S00001) has a GPA of 2.53 in Anthropology and an income of $73706. Eligible financial aid: Behavioral and Social Sciences Grant. Requirements met: Field of Study in Behavioral and Social Sciences.\n"
     ]
    }
   ],
   "source": [
    "def format(student: dict) -> str:\n",
    "    \"\"\"\n",
    "    Converts the retrieved student and financial aid knowledge into an LLM-readable prompt.\n",
    "    \"\"\"\n",
    "    return f\"Recipient {student['name']} (ID: {student['id']}) has a GPA of {student['gpa']} in {student['field_of_study']} \" + \\\n",
    "        f\"and an income of ${student['income']}. \" + \\\n",
    "        f\"Eligible financial aid: {', '.join(student['financial_aid']) if student.get('financial_aid') else 'None'}. \" + \\\n",
    "        f\"Requirements met: {', '.join(student['requirements']) if student.get('requirements') else 'None'}.\"\n",
    "\n",
    "\n",
    "retrieved_knowledge = retrieve_financial_aid_knowledge(\"S00001\")\n",
    "print(retrieved_knowledge)  # Data as-is\n",
    "print(format(retrieved_knowledge)) # Data formatted for LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Pre-build all prompts using synthetic population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T21:09:50.038146Z",
     "iopub.status.busy": "2025-02-28T21:09:50.037805Z",
     "iopub.status.idle": "2025-02-28T21:09:50.042828Z",
     "shell.execute_reply": "2025-02-28T21:09:50.041875Z",
     "shell.execute_reply.started": "2025-02-28T21:09:50.038120Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "\n",
    "def build_student_prompt(user_input: str, student_id: Optional[str] = None) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Builds student chat prompt for LLM and uses RAG to keep responses properly informed for\n",
    "    the given student with student_id.\n",
    "    \"\"\"\n",
    "\n",
    "    # student id available and valid, proceed with lookup\n",
    "    knowledge = format(retrieve_financial_aid_knowledge(student_id))\n",
    "\n",
    "    # Retrun both the knowledge rertieved and the prompt\n",
    "    return (\n",
    "        knowledge,\n",
    "        f\"\"\"\n",
    "        ### Role: You are a financial aid evaluator. Answer the user's question based on the provided student's profile. Do not repeat the question or context, do not add any data not available regarding funding amount or renewals. Make sure to use the eligible financial aid and requirements met to inform their eligibility. \\n\\n### Context:\\n{knowledge}\\n\\n### User's Question:\\n{user_input}\\n\\n###Answer: \n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T21:09:51.830451Z",
     "iopub.status.busy": "2025-02-28T21:09:51.830147Z",
     "iopub.status.idle": "2025-02-28T21:09:51.869571Z",
     "shell.execute_reply": "2025-02-28T21:09:51.868597Z",
     "shell.execute_reply.started": "2025-02-28T21:09:51.830429Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\n        ### Role: You are a financial aid evaluator. Answer the user's question based on the provided student's profile. Do not repeat the question or context, do not add any data not available regarding funding amount or renewals. Make sure to use the eligible financial aid and requirements met to inform their eligibility. \\n\\n### Context:\\nRecipient Marc Solomon (ID: S00001) has a GPA of 2.53 in Anthropology and an income of $73706. Eligible financial aid: Behavioral and Social Sciences Grant. Requirements met: Field of Study in Behavioral and Social Sciences.\\n\\n### User's Question:\\nWhat grants can I apply for?\\n\\n###Answer: \\n        \",\n",
       " \"\\n        ### Role: You are a financial aid evaluator. Answer the user's question based on the provided student's profile. Do not repeat the question or context, do not add any data not available regarding funding amount or renewals. Make sure to use the eligible financial aid and requirements met to inform their eligibility. \\n\\n### Context:\\nRecipient Suzanne Kidd (ID: S00002) has a GPA of 2.5 in Business Administration and an income of $22259. Eligible financial aid: None. Requirements met: Income ≤ $35,000.\\n\\n### User's Question:\\nWhat GPA do I need need to qualify for financial aid?\\n\\n###Answer: \\n        \",\n",
       " \"\\n        ### Role: You are a financial aid evaluator. Answer the user's question based on the provided student's profile. Do not repeat the question or context, do not add any data not available regarding funding amount or renewals. Make sure to use the eligible financial aid and requirements met to inform their eligibility. \\n\\n### Context:\\nRecipient Michelle Griffin (ID: S00003) has a GPA of 2.42 in Political Science and an income of $31192. Eligible financial aid: None. Requirements met: Income ≤ $35,000.\\n\\n### User's Question:\\nWhat GPA do I need need to qualify for financial aid?\\n\\n###Answer: \\n        \",\n",
       " \"\\n        ### Role: You are a financial aid evaluator. Answer the user's question based on the provided student's profile. Do not repeat the question or context, do not add any data not available regarding funding amount or renewals. Make sure to use the eligible financial aid and requirements met to inform their eligibility. \\n\\n### Context:\\nRecipient Hannah Dixon (ID: S00004) has a GPA of 2.05 in Engineering and an income of $530431. Eligible financial aid: STEM Excellence Award. Requirements met: Field of Study in STEM.\\n\\n### User's Question:\\nWhat grants can I apply for?\\n\\n###Answer: \\n        \",\n",
       " \"\\n        ### Role: You are a financial aid evaluator. Answer the user's question based on the provided student's profile. Do not repeat the question or context, do not add any data not available regarding funding amount or renewals. Make sure to use the eligible financial aid and requirements met to inform their eligibility. \\n\\n### Context:\\nRecipient Mary Harris (ID: S00005) has a GPA of 3.13 in Chemistry and an income of $370142. Eligible financial aid: None. Requirements met: None.\\n\\n### User's Question:\\nAm I eligible for scholarships?\\n\\n###Answer: \\n        \"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define test dataset (Example questions)\n",
    "def build_test_sentences():\n",
    "    test_sentences = [\n",
    "        f\"What GPA do I need need to qualify for financial aid?\",\n",
    "        f\"Am I eligible for scholarships?\",\n",
    "        f\"What grants can I apply for?\",\n",
    "    ]\n",
    "\n",
    "    return test_sentences\n",
    "\n",
    "student_prompts = []\n",
    "\n",
    "for student in fake_students:\n",
    "    test_sentence = random.choice(build_test_sentences())\n",
    "    knowledge_retrieved, prompt = build_student_prompt(user_input=test_sentence, student_id=student[\"id\"])\n",
    "    student_prompts.append(prompt)\n",
    "\n",
    "student_prompts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set to start testing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run custom student inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T21:06:26.909172Z",
     "iopub.status.busy": "2025-02-28T21:06:26.908857Z",
     "iopub.status.idle": "2025-02-28T21:06:35.443679Z",
     "shell.execute_reply": "2025-02-28T21:06:35.442941Z",
     "shell.execute_reply.started": "2025-02-28T21:06:26.909146Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /Users/erosado/work/rag-ai-chat-template/notebooks/dist/models/phi4_mini/chat/v1.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82583bea2b4c44fa925c437b7937ff1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully and set to use mps!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from chat_ai.src.adapters.llms.model_loader_adapter import ModelLoaderAdapter\n",
    "\n",
    "# Load fine-tuned model (the final merged version)\n",
    "tuned_model_storage_path = f\"notebooks/dist/models/phi4_mini/chat\"\n",
    "\n",
    "model_loader = ModelLoaderAdapter(\n",
    "    model_name=\"PHI4StudentChatModel\",\n",
    "    model_path=tuned_model_storage_path,\n",
    "    model_version=\"1.0\",\n",
    "    model_type=\"generation\",\n",
    ")\n",
    "\n",
    "model, tokenizer = model_loader.load_pretrained_model()\n",
    "\n",
    "# model.to(device)  TODO: Figure out the cause behind mps device movement failure\n",
    "model = torch.compile(model) # To boost inference speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T21:09:56.182272Z",
     "iopub.status.busy": "2025-02-28T21:09:56.181969Z",
     "iopub.status.idle": "2025-02-28T21:09:56.188895Z",
     "shell.execute_reply": "2025-02-28T21:09:56.187828Z",
     "shell.execute_reply.started": "2025-02-28T21:09:56.182248Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n        ### Role: You are a financial aid evaluator. Answer the user's question based on the provided student's profile. Do not repeat the question or context, do not add any data not available regarding funding amount or renewals. Make sure to use the eligible financial aid and requirements met to inform their eligibility. \\n\\n### Context:\\nRecipient Sandra James (ID: S00168) has a GPA of 2.9 in Art and an income of $326828. Eligible financial aid: None. Requirements met: None.\\n\\n### User's Question:\\nWhat GPA do I need need to qualify for financial aid?\\n\\n###Answer: \\n        \""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select first prompt\n",
    "first_prompt = random.choice(student_prompts)\n",
    "first_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T21:10:15.057324Z",
     "iopub.status.busy": "2025-02-28T21:10:15.057003Z",
     "iopub.status.idle": "2025-02-28T21:10:15.061475Z",
     "shell.execute_reply": "2025-02-28T21:10:15.060678Z",
     "shell.execute_reply.started": "2025-02-28T21:10:15.057300Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_answer(response_text):\n",
    "    \"\"\"\n",
    "    Extracts the generated answer from the LLM response.\n",
    "    \"\"\"\n",
    "\n",
    "    # Match the last \"Answer:\" followed by actual content\n",
    "    match = re.search(\n",
    "        r\"(?i)(?:Your response:|Answer:)\\s*\\n*(.*?)(?=\\n\\n|\\Z)\",\n",
    "        response_text,\n",
    "        re.DOTALL,\n",
    "    )\n",
    "\n",
    "    if match:\n",
    "        extracted_answer = match.group(1).strip()\n",
    "        return extracted_answer\n",
    "    else:\n",
    "        return \"No answer found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T21:10:16.312551Z",
     "iopub.status.busy": "2025-02-28T21:10:16.312257Z",
     "iopub.status.idle": "2025-02-28T21:10:28.148053Z",
     "shell.execute_reply": "2025-02-28T21:10:28.147234Z",
     "shell.execute_reply.started": "2025-02-28T21:10:16.312527Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sandra James does not qualify for any financial aid as there are no eligible financial aid options available for her, and she has not met any requirements for financial aid.\n"
     ]
    }
   ],
   "source": [
    "device = model_loader.get_device()\n",
    "def generate_text(prompt, max_new_tokens=100):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Run first prompt\n",
    "response = generate_text(first_prompt)\n",
    "print(extract_answer(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T21:10:44.021805Z",
     "iopub.status.busy": "2025-02-28T21:10:44.021475Z",
     "iopub.status.idle": "2025-02-28T21:10:53.681879Z",
     "shell.execute_reply": "2025-02-28T21:10:53.680692Z",
     "shell.execute_reply.started": "2025-02-28T21:10:44.021777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you are eligible for the STEM Excellence Award.\n"
     ]
    }
   ],
   "source": [
    "# Run another prompt\n",
    "response = generate_text(random.choice(student_prompts))\n",
    "print(extract_answer(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate Model\n",
    "\n",
    "### TBD - requires uploading separate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Deploy to S3\n",
    "The following is entirely optional and requires an AWS account. The author assumes the user has set up their AWS CLI and is authenticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 = boto3.client(\"s3\")\n",
    "# bucket_name = \"your-sagemaker-bucket\"\n",
    "\n",
    "# # Upload merged model to S3\n",
    "# s3.upload_file(tuned_model_storage_dir, bucket_name, s3_model_storage_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11243363,
     "datasetId": 6758176,
     "sourceId": 10876989,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
